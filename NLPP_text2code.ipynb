{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t-0_Q8V2GwH"
      },
      "source": [
        "for local:  \n",
        "start jupyter using:\n",
        "```\n",
        "jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0\n",
        "```\n",
        "(I need to run as admin)\n",
        "\n",
        "and set `run_local = True`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efydMZjh7iJA"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iIcR467b0b2b"
      },
      "outputs": [],
      "source": [
        "run_local = False\n",
        "download = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJVfHLJMG99h"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xIVgGr7i0XCW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "if run_local:\n",
        "  os.environ['TRANSFORMERS_CACHE'] = \"/Users/Martin/.cache/huggingface/transformers\"\n",
        "\n",
        "  %cd \"Jupyter Notebook/WS21 NLP (Project)/colab/\"\n",
        "  if download:\n",
        "    !pip install wget\n",
        "    !python -m wget https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
        "\n",
        "  data_processing_batch_cpu = 20_000\n",
        "  data_processing_batch_gpu = 100\n",
        "  batch_size_hugging = 25\n",
        "  batch_size_tf = 25\n",
        "else:\n",
        "  if download:\n",
        "    !wget https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
        "\n",
        "  data_processing_batch_cpu = 1_000\n",
        "  data_processing_batch_gpu = 100\n",
        "  batch_size_hugging = 50\n",
        "  batch_size_tf = 50\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  pt_device = torch.device('cuda:0')\n",
        "else:\n",
        "  pt_device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZUNxGvTe7YC",
        "outputId": "bd24f288-6bca-406a-9216-42a1f1d1c059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 45.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 47.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install tqdm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import default_rng\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import math\n",
        "import re\n",
        "from typing import List, Optional, Union\n",
        "from collections.abc import Sized\n",
        "import ast\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Bidirectional, LSTM, Embedding, TimeDistributed\n",
        "from tensorflow.keras.utils import plot_model, Sequence\n",
        "from tensorflow.keras.models import load_model\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, IterableDataset\n",
        "from transformers.trainer_pt_utils import (\n",
        "    nested_concat,\n",
        "    find_batch_size,\n",
        "    nested_numpify,\n",
        "    nested_truncate\n",
        ")\n",
        "from transformers.trainer_utils import (\n",
        "    EvalLoopOutput,\n",
        "    PredictionOutput,\n",
        "    EvalPrediction,\n",
        "    denumpify_detensorize\n",
        ")\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    BertConfig,\n",
        "    EncoderDecoderConfig,\n",
        "    EncoderDecoderModel,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "rng = default_rng()\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if len(gpus) > 0:\n",
        "  # does not magically solve all problems, but suprisingly a few.\n",
        "  tf.config.experimental.set_memory_growth(gpus[0], True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yaoq7L4W7zCH"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download"
      ],
      "metadata": {
        "id": "mPs2ljwzgtiF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vHuM6H6hz88",
        "outputId": "58fb53c4-037d-434a-f421-92a950f72688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  python.zip\n",
            "   creating: python/               \n",
            "   creating: python/final/         \n",
            "   creating: python/final/jsonl/   \n",
            "   creating: python/final/jsonl/train/\n",
            "  inflating: python/final/jsonl/train/python_train_9.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_12.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_10.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_0.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_6.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_2.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_4.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_8.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_11.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_5.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_13.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_3.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_1.jsonl.gz  \n",
            "  inflating: python/final/jsonl/train/python_train_7.jsonl.gz  \n",
            "   creating: python/final/jsonl/test/\n",
            "  inflating: python/final/jsonl/test/python_test_0.jsonl.gz  \n",
            "   creating: python/final/jsonl/valid/\n",
            "  inflating: python/final/jsonl/valid/python_valid_0.jsonl.gz  \n",
            "  inflating: python_dedupe_definitions_v2.pkl  \n",
            "  inflating: python_licenses.pkl     \n"
          ]
        }
      ],
      "source": [
        "!unzip python.zip\n",
        "with open('python_dedupe_definitions_v2.pkl', 'rb') as f:\n",
        "    py_data = pickle.load(f)\n",
        "os.remove(\"python.zip\")\n",
        "\n",
        "os.remove(\"python_dedupe_definitions_v2.pkl\")\n",
        "os.remove(\"python_licenses.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAhFZJ3liMI6"
      },
      "source": [
        "Only for achieving the same train, val, test split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1tHMjQYu-mF"
      },
      "outputs": [],
      "source": [
        "columns_list_short = ['path', 'repo', 'func_name', 'code', 'sha', 'partition']\n",
        "columns_list = ['path', 'repo', 'func_name', 'code', 'docstring', 'docstring_full', 'sha', 'partition']\n",
        "\n",
        "def jsonl_list_to_dataframe(file_list, columns=columns_list_short):\n",
        "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
        "    return pd.concat([pd.read_json(f, \n",
        "                                   orient='records', \n",
        "                                   compression='gzip',\n",
        "                                   lines=True)[columns] \n",
        "                      for f in file_list], sort=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgekbzaFzwE7"
      },
      "outputs": [],
      "source": [
        "python_files = sorted(Path('python').glob('**/*.gz'))\n",
        "pydf_split = jsonl_list_to_dataframe(python_files)\n",
        "\n",
        "shutil.rmtree(\"python\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOpmpdhO0htE"
      },
      "source": [
        "## Look at data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0bChtA_JKZT",
        "outputId": "3d2c2952-e6b8-43f7-c92f-e4d3591f454c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['path', 'repo', 'func_name', 'code', 'docstring', 'docstring_full',\n",
              "       'sha', 'partition'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "pydf_large = pd.DataFrame(py_data)[['path', 'nwo', 'identifier', 'function', 'docstring_summary', 'docstring', 'sha']]\n",
        "del py_data\n",
        "\n",
        "pydf_large['partition']='undefined'\n",
        "pydf_large.columns = columns_list\n",
        "pydf_large.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35eVMfYc7XtX",
        "outputId": "49ed6548-9cd9-473f-92a6-49926969f901"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "path                               examples/face_recognition_knn.py\n",
              "repo                                      ageitgey/face_recognition\n",
              "func_name                                                     train\n",
              "code              def train(train_dir, model_save_path=None, n_n...\n",
              "docstring         Trains a k-nearest neighbors classifier for fa...\n",
              "docstring_full    Trains a k-nearest neighbors classifier for fa...\n",
              "sha                        c96b010c02f15e8eeb0f71308c641179ac1f19bb\n",
              "partition                                                 undefined\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "pydf_large.iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a \"sha\" column included in the data. We will however not use this value to merge the data, as it is not unique (does not include function name or code)."
      ],
      "metadata": {
        "id": "Yr9V8dclhGL_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "PlCHeQLU2jOr",
        "outputId": "f6358d4c-5c36-48b5-829d-f3a28fa29bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicated sha 98.52 %\n",
            "Unduplicated sha 1.48 %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      path  \\\n",
              "1                         examples/face_recognition_knn.py   \n",
              "2                         examples/face_recognition_knn.py   \n",
              "3        examples/web_service_example_Simplified_Chines...   \n",
              "4        examples/web_service_example_Simplified_Chines...   \n",
              "5                   face_recognition/face_detection_cli.py   \n",
              "...                                                    ...   \n",
              "1156080                      src/pyokit/datastruct/read.py   \n",
              "1156081                      src/pyokit/datastruct/read.py   \n",
              "1156082                      src/pyokit/datastruct/read.py   \n",
              "1156083                      src/pyokit/datastruct/read.py   \n",
              "1156084                      src/pyokit/datastruct/read.py   \n",
              "\n",
              "                              repo  \\\n",
              "1        ageitgey/face_recognition   \n",
              "2        ageitgey/face_recognition   \n",
              "3        ageitgey/face_recognition   \n",
              "4        ageitgey/face_recognition   \n",
              "5        ageitgey/face_recognition   \n",
              "...                            ...   \n",
              "1156080              pjuren/pyokit   \n",
              "1156081              pjuren/pyokit   \n",
              "1156082              pjuren/pyokit   \n",
              "1156083              pjuren/pyokit   \n",
              "1156084              pjuren/pyokit   \n",
              "\n",
              "                                            func_name  \\\n",
              "1                                             predict   \n",
              "2                     show_prediction_labels_on_image   \n",
              "3                                        upload_image   \n",
              "4                               detect_faces_in_image   \n",
              "5                                        print_result   \n",
              "...                                               ...   \n",
              "1156080                NGSReadUnitTests.test_rev_comp   \n",
              "1156081                   NGSReadUnitTests.test_split   \n",
              "1156082                       NGSReadUnitTests.testeq   \n",
              "1156083              NGSReadUnitTests.testClipadaptor   \n",
              "1156084  NGSReadUnitTests.testGetRelativeQualityScore   \n",
              "\n",
              "                                                      code  \\\n",
              "1        def predict(X_img_path, knn_clf=None, model_pa...   \n",
              "2        def show_prediction_labels_on_image(img_path, ...   \n",
              "3        def upload_image():\\n    # 检测图片是否上传成功\\n    if ...   \n",
              "4        def detect_faces_in_image(file_stream):\\n    #...   \n",
              "5        def print_result(filename, location):\\n    top...   \n",
              "...                                                    ...   \n",
              "1156080  def test_rev_comp(self):\\n    self.r1.reverse_...   \n",
              "1156081  def test_split(self):\\n    self.assertEquals(s...   \n",
              "1156082  def testeq(self):\\n    \"\"\"\\n      test the equ...   \n",
              "1156083  def testClipadaptor(self):\\n    input_seq = NG...   \n",
              "1156084  def testGetRelativeQualityScore(self):\\n    in...   \n",
              "\n",
              "                                                 docstring  \\\n",
              "1        Recognizes faces in given image using a traine...   \n",
              "2             Shows the face recognition results visually.   \n",
              "3                                                            \n",
              "4                                                            \n",
              "5                                                            \n",
              "...                                                    ...   \n",
              "1156080                                                      \n",
              "1156081                                                      \n",
              "1156082  test the equality operator for NGSRead sequences.   \n",
              "1156083                                                      \n",
              "1156084                                                      \n",
              "\n",
              "                                            docstring_full  \\\n",
              "1        Recognizes faces in given image using a traine...   \n",
              "2        Shows the face recognition results visually.\\n...   \n",
              "3                                                            \n",
              "4                                                            \n",
              "5                                                            \n",
              "...                                                    ...   \n",
              "1156080                                                      \n",
              "1156081                                                      \n",
              "1156082  test the equality operator for NGSRead sequences.   \n",
              "1156083                                                      \n",
              "1156084                                                      \n",
              "\n",
              "                                              sha  partition  \n",
              "1        c96b010c02f15e8eeb0f71308c641179ac1f19bb  undefined  \n",
              "2        c96b010c02f15e8eeb0f71308c641179ac1f19bb  undefined  \n",
              "3        c96b010c02f15e8eeb0f71308c641179ac1f19bb  undefined  \n",
              "4        c96b010c02f15e8eeb0f71308c641179ac1f19bb  undefined  \n",
              "5        c96b010c02f15e8eeb0f71308c641179ac1f19bb  undefined  \n",
              "...                                           ...        ...  \n",
              "1156080  fddae123b5d817daa39496183f19c000d9c3791f  undefined  \n",
              "1156081  fddae123b5d817daa39496183f19c000d9c3791f  undefined  \n",
              "1156082  fddae123b5d817daa39496183f19c000d9c3791f  undefined  \n",
              "1156083  fddae123b5d817daa39496183f19c000d9c3791f  undefined  \n",
              "1156084  fddae123b5d817daa39496183f19c000d9c3791f  undefined  \n",
              "\n",
              "[1138943 rows x 8 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>repo</th>\n",
              "      <th>func_name</th>\n",
              "      <th>code</th>\n",
              "      <th>docstring</th>\n",
              "      <th>docstring_full</th>\n",
              "      <th>sha</th>\n",
              "      <th>partition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>examples/face_recognition_knn.py</td>\n",
              "      <td>ageitgey/face_recognition</td>\n",
              "      <td>predict</td>\n",
              "      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n",
              "      <td>Recognizes faces in given image using a traine...</td>\n",
              "      <td>Recognizes faces in given image using a traine...</td>\n",
              "      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n",
              "      <td>undefined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>examples/face_recognition_knn.py</td>\n",
              "      <td>ageitgey/face_recognition</td>\n",
              "      <td>show_prediction_labels_on_image</td>\n",
              "      <td>def show_prediction_labels_on_image(img_path, ...</td>\n",
              "      <td>Shows the face recognition results visually.</td>\n",
              "      <td>Shows the face recognition results visually.\\n...</td>\n",
              "      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n",
              "      <td>undefined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>examples/web_service_example_Simplified_Chines...</td>\n",
              "      <td>ageitgey/face_recognition</td>\n",
              "      <td>upload_image</td>\n",
              "      <td>def upload_image():\\n    # 检测图片是否上传成功\\n    if ...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n",
              "      <td>undefined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>examples/web_service_example_Simplified_Chines...</td>\n",
              "      <td>ageitgey/face_recognition</td>\n",
              "      <td>detect_faces_in_image</td>\n",
              "      <td>def detect_faces_in_image(file_stream):\\n    #...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n",
              "      <td>undefined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>face_recognition/face_detection_cli.py</td>\n",
              "      <td>ageitgey/face_recognition</td>\n",
              "      <td>print_result</td>\n",
              "      <td>def print_result(filename, location):\\n    top...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>c96b010c02f15e8eeb0f71308c641179ac1f19bb</td>\n",
              "      <td>undefined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156080</th>\n",
              "      <td>src/pyokit/datastruct/read.py</td>\n",
              "      <td>pjuren/pyokit</td>\n",
              "      <td>NGSReadUnitTests.test_rev_comp</td>\n",
              "      <td>def test_rev_comp(self):\\n    self.r1.reverse_...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>fddae123b5d817daa39496183f19c000d9c3791f</td>\n",
              "      <td>undefined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156081</th>\n",
              "      <td>src/pyokit/datastruct/read.py</td>\n",
              "      <td>pjuren/pyokit</td>\n",
              "      <td>NGSReadUnitTests.test_split</td>\n",
              "      <td>def test_split(self):\\n    self.assertEquals(s...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>fddae123b5d817daa39496183f19c000d9c3791f</td>\n",
              "      <td>undefined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156082</th>\n",
              "      <td>src/pyokit/datastruct/read.py</td>\n",
              "      <td>pjuren/pyokit</td>\n",
              "      <td>NGSReadUnitTests.testeq</td>\n",
              "      <td>def testeq(self):\\n    \"\"\"\\n      test the equ...</td>\n",
              "      <td>test the equality operator for NGSRead sequences.</td>\n",
              "      <td>test the equality operator for NGSRead sequences.</td>\n",
              "      <td>fddae123b5d817daa39496183f19c000d9c3791f</td>\n",
              "      <td>undefined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156083</th>\n",
              "      <td>src/pyokit/datastruct/read.py</td>\n",
              "      <td>pjuren/pyokit</td>\n",
              "      <td>NGSReadUnitTests.testClipadaptor</td>\n",
              "      <td>def testClipadaptor(self):\\n    input_seq = NG...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>fddae123b5d817daa39496183f19c000d9c3791f</td>\n",
              "      <td>undefined</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156084</th>\n",
              "      <td>src/pyokit/datastruct/read.py</td>\n",
              "      <td>pjuren/pyokit</td>\n",
              "      <td>NGSReadUnitTests.testGetRelativeQualityScore</td>\n",
              "      <td>def testGetRelativeQualityScore(self):\\n    in...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>fddae123b5d817daa39496183f19c000d9c3791f</td>\n",
              "      <td>undefined</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1138943 rows × 8 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len_dup=len(pydf_large[pydf_large.duplicated('sha')])\n",
        "\n",
        "print(f\"Duplicated sha {len_dup/len(pydf_large)* 100:.2f} %\")\n",
        "print(f\"Unduplicated sha {(len(pydf_large)-len_dup)/len(pydf_large) * 100:.2f} %\")\n",
        "pydf_large[pydf_large.duplicated('sha')]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K7ZU5oP7Ind"
      },
      "source": [
        "We have to create our own Hash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oN5JgLScr-1"
      },
      "outputs": [],
      "source": [
        "pydf_split['own_hash'] = pydf_split.apply(lambda row: hash((row['repo'], row['path'], row['func_name'], row['code'])), axis=1)\n",
        "pydf_large['own_hash'] = pydf_large.apply(lambda row: hash((row['repo'], row['path'], row['func_name'], row['code'])), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "67wcMolf-pGI",
        "outputId": "7dbd5909-c8e4-4289-a998-b645463e9934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicated own_hash 0.00 %\n",
            "Unduplicated own_hash 100.00 %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [path, repo, func_name, code, docstring, docstring_full, sha, partition, own_hash]\n",
              "Index: []"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>repo</th>\n",
              "      <th>func_name</th>\n",
              "      <th>code</th>\n",
              "      <th>docstring</th>\n",
              "      <th>docstring_full</th>\n",
              "      <th>sha</th>\n",
              "      <th>partition</th>\n",
              "      <th>own_hash</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len_dup=len(pydf_large[pydf_large.duplicated('own_hash')])\n",
        "\n",
        "print(f\"Duplicated own_hash {len_dup/len(pydf_large)* 100:.2f} %\")\n",
        "print(f\"Unduplicated own_hash {(len(pydf_large)-len_dup)/len(pydf_large) * 100:.2f} %\")\n",
        "pydf_large[pydf_large.duplicated('own_hash')]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets can now be savely merged."
      ],
      "metadata": {
        "id": "58DvOQCkhySh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2lvKxf9Kh3t"
      },
      "outputs": [],
      "source": [
        "pydf = pd.merge(pydf_large, pydf_split, on='own_hash', how='left')[['code_x',\n",
        "                                                                    'docstring',\n",
        "                                                                    'docstring_full',\n",
        "                                                                    'partition_y']]\n",
        "pydf.columns=['code', 'docstring', 'docstring_full', 'partition']\n",
        "pydf.fillna('train', inplace=True)\n",
        "\n",
        "pydf.to_pickle(\"python_data_partitioned.pkl\")\n",
        "pydf_size = len(pydf)\n",
        "del pydf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HFHi3tiAQ1W"
      },
      "source": [
        "We use the following function multiple times in the notebook in order to limit the amount of data loaded into memory at a time. On our machines this function was needed to avoid a crash, although we still load the finished dataframe into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUywtwMkAPiB"
      },
      "outputs": [],
      "source": [
        "def batch_read_apply(pickle_file, df_lines, batch_size, new_columns):\n",
        "  !mkdir batch_process\n",
        "\n",
        "  df_full = pd.read_pickle(pickle_file)\n",
        "\n",
        "  for batch_start in tqdm(range(1, df_lines, batch_size), unit_scale=batch_size, unit=\"rows\"):\n",
        "    df_batch = df_full.iloc[batch_start : batch_start + batch_size].copy()\n",
        "    # to help with tokenization.\n",
        "    df_batch.fillna(\"\", inplace=True)\n",
        "\n",
        "    for col_name, func in new_columns.items():\n",
        "      new_col = func(df_batch)\n",
        "      df_batch[col_name] = new_col\n",
        "\n",
        "    df_batch.to_pickle(f\"batch_process/python_data_token_{batch_start - 1}.pkl\")\n",
        "  \n",
        "  final_df = pd.concat([pd.read_pickle(os.path.join(\"batch_process\", f))\n",
        "                        for f in os.listdir(\"batch_process/\")],\n",
        "                       ignore_index=True,\n",
        "                       verify_integrity=True)\n",
        "  \n",
        "  shutil.rmtree(\"batch_process\")\n",
        "\n",
        "  return final_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now remove the docstring from the code column. This was done for the dataset w/ docstring, but not for the full.\n",
        "\n",
        "We did a mistake here by only removing regular quoted docstrings and not single quoted (\" \" \"  vs ' ' ')"
      ],
      "metadata": {
        "id": "80KLRxiakLNx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_hFCmrlAapc",
        "outputId": "11fdc2b0-4c29-42d1-bc29-f3405962a3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████| 1160000/1160000 [06:15<00:00, 3093.23rows/s]\n"
          ]
        }
      ],
      "source": [
        "def remove_docstring(df):\n",
        "  cleaned_code = []\n",
        "  for _, row in df.iterrows():\n",
        "    doc_search = '\"\"\"\\s*' + re.escape(row[\"docstring_full\"]) + '\\s*\"\"\"\\s*'\n",
        "    doc_match = re.search(doc_search, row[\"code\"])\n",
        "\n",
        "    if doc_match is None:\n",
        "      cleaned_code += [row[\"code\"]]\n",
        "    else:\n",
        "      doc_start, doc_end = doc_match.span()\n",
        "      cleaned_code += [row[\"code\"][:doc_start] + row[\"code\"][doc_end:]]\n",
        "  \n",
        "  return cleaned_code\n",
        "\n",
        "pydf = batch_read_apply(\"python_data_partitioned.pkl\",\n",
        "                        pydf_size,\n",
        "                        batch_size=data_processing_batch_cpu,\n",
        "                        new_columns={\"clean_code\": remove_docstring})\n",
        "\n",
        "pydf.to_pickle(\"python_data_partitioned.pkl\")\n",
        "del pydf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbk5M25aVuVX"
      },
      "source": [
        "## Data selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7aAT9xcRaLq"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base-multi-sum\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/codet5-base-multi-sum\")\n",
        "model.to(pt_device)\n",
        "\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDX4KOX9XxM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11182e68-f3e1-4251-ca6d-aaecb2bb5565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|                                                                                    | 0/1160000 [00:00<?, ?rows/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1543 > 512). Running this sequence through the model will result in indexing errors\n",
            "100%|████████████████████████████████████████████████████████████████████| 1160000/1160000 [02:54<00:00, 6633.17rows/s]\n"
          ]
        }
      ],
      "source": [
        "token_columns = {\"code_token_jagged\": lambda df: tokenizer(df['clean_code'].tolist()).input_ids,\n",
        "                 \"docstring_token_jagged\": lambda df: tokenizer(df['docstring'].tolist()).input_ids}\n",
        "\n",
        "pydf = batch_read_apply(\"python_data_partitioned.pkl\",\n",
        "                        pydf_size,\n",
        "                        batch_size=data_processing_batch_cpu,\n",
        "                        new_columns=token_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot for data selection results\n",
        "\n",
        "we exclude all functions:\n",
        "- with more than 100 token in the tokenized function code\n",
        "- with more than 100 token in the tokenized function docstring\n",
        "- whose first parameter is \"self\".\n",
        "\n",
        "we did a mistake on the last point for the data used:  \n",
        "we do not exclude functions like `def fnc( self, other):`, only `def fnc( self, other):`. The difference is also in the plot."
      ],
      "metadata": {
        "id": "a1VPaR_jKTCu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsg8eJl0Y1Zq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "142194e7-7a31-450b-d728-c1c9e4f40120"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Max length function code:                1213070\n",
            "Max length function docstring:              3667\n",
            "Functions with less than 100 tokens in code\n",
            "  and less than 100 token in docstring:       47.14%\n",
            "Functions that are not methods:               32.11% (33.09% used for data)\n",
            "Eligible functions:                           12.24%\n",
            "\n",
            "Final test set will (still) have:          22176 (largest code: 6573, doc: 2682)\n",
            "Final validation set will have:             3385 (14.65% of full validation set)\n",
            "Final train set will have:                135242 (12.18% of full train set)\n"
          ]
        }
      ],
      "source": [
        "code_cutoff = 100\n",
        "doc_cutoff = 100\n",
        "\n",
        "def plot_lengths(df, cutoff, name):\n",
        "  length_col = f\"{name} Len\"\n",
        "\n",
        "  ax = df[df[length_col] < 500][length_col].plot.hist(bins=100, figsize=(12, 7))\n",
        "  ax.set_xlabel(\"Number Tokens\")\n",
        "  ax.set_title(f\"{name} length distribution of dataset\")\n",
        "  plt.show()\n",
        "\n",
        "pydf[\"Docstring Len\"] = pydf[\"docstring_token_jagged\"].str.len()\n",
        "pydf[\"Code Len\"] = pydf[\"code_token_jagged\"].str.len()\n",
        "\n",
        "plot_lengths(pydf, doc_cutoff, \"Docstring\")\n",
        "plot_lengths(pydf, code_cutoff, \"Code\")\n",
        "\n",
        "not_method_condition = ~(pydf[\"clean_code\"].str.contains(\"^(?:async )?def\\s[^(]+\\(self\"))\n",
        "not_method_cond_corrected = ~(pydf[\"clean_code\"].str.contains(\"^(?:async )?def\\s[^(]+\\(\\s*self\"))\n",
        "below_limit_condition = (pydf[\"Docstring Len\"] <= doc_cutoff) & (pydf[\"Code Len\"] <= code_cutoff)\n",
        "condition = not_method_condition & below_limit_condition\n",
        "\n",
        "below_limit = len(pydf[below_limit_condition]) / len(pydf)\n",
        "not_method = len(pydf[not_method_condition]) / len(pydf)\n",
        "not_method_corrected = len(pydf[not_method_cond_corrected]) / len(pydf)\n",
        "condition_percent = len(pydf[condition]) / len(pydf)\n",
        "largest_code = max(pydf[\"Code Len\"])\n",
        "largest_doc = max(pydf[\"Docstring Len\"])\n",
        "full_train = len(pydf[pydf['partition'] == 'train'])\n",
        "# final train data files ended up with one less example. We do not know why.\n",
        "train_size = len(pydf[(pydf['partition'] == 'train') & condition]) - 1\n",
        "full_test = len(pydf[pydf['partition'] == 'test'])\n",
        "largest_test_code = max(pydf[(pydf['partition'] == 'test')][\"Code Len\"])\n",
        "largest_test_doc = max(pydf[(pydf['partition'] == 'test')][\"Docstring Len\"])\n",
        "full_val = len(pydf[pydf['partition'] == 'valid'])\n",
        "val_size = len(pydf[(pydf['partition'] == 'valid') & condition])\n",
        "\n",
        "print()\n",
        "print(f\"Max length function code:                {largest_code:7.0f}\")\n",
        "print(f\"Max length function docstring:           {largest_doc:7.0f}\")\n",
        "print(f\"Functions with less than {code_cutoff} tokens in code\")\n",
        "print(f\"  and less than {doc_cutoff} token in docstring:  {100 * below_limit:10.2f}%\")\n",
        "print(f\"Functions that are not methods:          {100 * not_method_corrected:10.2f}% \"\n",
        "      f\"({100 * not_method:5.2f}% used for data)\")\n",
        "print(f\"Eligible functions:                      {100 * condition_percent:10.2f}%\")\n",
        "print()\n",
        "\n",
        "print(f\"Final test set will (still) have:        {full_test:7.0f} \"\n",
        "      f\"(largest code: {largest_test_code}, doc: {largest_test_doc})\")\n",
        "print(f\"Final validation set will have:          {val_size:7.0f} \"\n",
        "      f\"({100 * val_size / full_val:5.2f}% of full validation set)\")\n",
        "print(f\"Final train set will have:               {train_size:7.0f} \"\n",
        "      f\"({100 * train_size / full_train:5.2f}% of full train set)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb8dC6mlc8cM"
      },
      "source": [
        "examples for a 100 token non-method function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zQZNdTrc7zB",
        "outputId": "aa711c4f-b5b3-4455-fc05-4cf9770cde48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples:\n",
            "def fetch_latest_stable_version():\n",
            "    response = urllib.urlopen(LATEST_VERSION_FILE_URL)\n",
            "    if response.getcode() == 200:\n",
            "        return response.read().strip()\n",
            "    else:\n",
            "        raise MongoctlException(\"Unable to fetch MongoDB latest stable version\"\n",
            "                                \" from '%s' (Response code %s)\" %\n",
            "                                (LATEST_VERSION_FILE_URL, response.getcode()))\n",
            "\n",
            "def main():\n",
            "    parser = argparse.ArgumentParser(description='Compose a yaml file.')\n",
            "    parser.add_argument(\n",
            "        'root',\n",
            "        type=argparse.FileType('r'),\n",
            "        help='The root yaml file to compose.'\n",
            "    )\n",
            "\n",
            "    args = parser.parse_args()\n",
            "\n",
            "    result = yaml.load(args.root, Loader=ComposeLoader)\n",
            "\n",
            "    print(yaml.dump(result))\n",
            "\n",
            "def _full_module_file_name_nosuffix(module_name):\n",
            "    module = sys.modules[module_name]\n",
            "    bn = os.path.basename(module.__file__).rpartition('.')[0]\n",
            "    if not (module.__package__ is None or module.__package__ == ''):\n",
            "        return module.__package__.replace('.', os.sep)+os.sep+bn\n",
            "    else:\n",
            "        return bn\n",
            "\n",
            "Example with particularly wierd names:\n",
            "\n",
            "def string_to_string(a_string):\n",
            "    a_string = to_str(a_string)\n",
            "    quote = '\"'\n",
            "    if '\"' in a_string:\n",
            "        quote = \"'\"\n",
            "    if \"'\" in a_string:\n",
            "        quote = '\"\"\"'\n",
            "    if \"/n\" in a_string:\n",
            "        quote = \"'''\"\n",
            "    return \"%s%s%s\" % (quote, a_string, quote)\n"
          ]
        }
      ],
      "source": [
        "code_sample_condition = (pydf[\"Code Len\"] == code_cutoff) & not_method_cond_corrected\n",
        "code_sample_random = rng.integers(len(pydf[code_sample_condition]), size=3)\n",
        "nice_bad_example = 1393\n",
        "\n",
        "print(\"Examples:\")\n",
        "print(pydf[code_sample_condition].iloc[code_sample_random[0]][\"clean_code\"])\n",
        "print()\n",
        "print(pydf[code_sample_condition].iloc[code_sample_random[1]][\"clean_code\"])\n",
        "print()\n",
        "print(pydf[code_sample_condition].iloc[code_sample_random[2]][\"clean_code\"])\n",
        "print(\"\\nExample with particularly wierd names:\\n\")\n",
        "print(pydf[code_sample_condition].iloc[nice_bad_example][\"clean_code\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY_FWM65A8cy"
      },
      "source": [
        "no longer jagged tokenization: use the consistent 100 token limit to make 2d array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZC5l_QF3KMO",
        "outputId": "4da33476-6be3-4e05-dae7-36142a9fe098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████| 1160000/1160000 [03:53<00:00, 4963.65rows/s]\n"
          ]
        }
      ],
      "source": [
        "retokenize = {\"code_token\": lambda df: tokenizer(df['clean_code'].tolist(),\n",
        "                                                 padding='max_length',\n",
        "                                                 max_length=code_cutoff).input_ids,\n",
        "              \"docstring_token\": lambda df: tokenizer(df['docstring'].tolist(),\n",
        "                                                      padding='max_length',\n",
        "                                                      max_length=doc_cutoff).input_ids}\n",
        "\n",
        "pydf = batch_read_apply(\"python_data_partitioned.pkl\",\n",
        "                        pydf_size,\n",
        "                        batch_size=data_processing_batch_cpu,\n",
        "                        new_columns=retokenize)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Test, Validation data"
      ],
      "metadata": {
        "id": "MZZ426TZlH_G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmEH8N-_J25R"
      },
      "outputs": [],
      "source": [
        "os.remove(\"python_data_partitioned.pkl\")\n",
        "pydf[\"Code Len\"] = pydf[\"code_token\"].str.len()\n",
        "\n",
        "!mkdir valid\n",
        "val_df = pydf[(pydf[\"partition\"] == \"valid\") & condition]\n",
        "val_X = np.array(val_df[\"docstring_token\"].tolist())\n",
        "val_y = np.array(val_df[\"code_token\"].tolist())\n",
        "with open(\"valid/python_data_validation.pkl\", \"wb\") as f:\n",
        "  pickle.dump((val_X, val_y), f)\n",
        "\n",
        "!mkdir test\n",
        "test_X = pydf[pydf[\"partition\"] == \"test\"][\"docstring_token\"].tolist()\n",
        "test_y = pydf[pydf[\"partition\"] == \"test\"][\"code_token\"].tolist()\n",
        "with open(\"test/python_data_test.pkl\", \"wb\") as f:\n",
        "  pickle.dump((test_X, test_y), f)\n",
        "\n",
        "pydf[(pydf[\"partition\"] == \"train\") & condition].to_pickle(\"python_data_train_initial.pkl\")\n",
        "\n",
        "del pydf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model reversing / data augentation\n",
        "\n",
        "only for the train data."
      ],
      "metadata": {
        "id": "4td-xSwAkwuT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syt2CgcFcVBT",
        "outputId": "ef0de9e7-28c5-423e-842b-0645be216569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████| 135300/135300 [11:16<00:00, 200.03rows/s]\n"
          ]
        }
      ],
      "source": [
        "def generate_docstrings(df):\n",
        "  input_ids = tokenizer(df[\"clean_code\"].tolist(),\n",
        "                        return_tensors=\"pt\",\n",
        "                        padding=\"max_length\",\n",
        "                        max_length=code_cutoff).input_ids\n",
        "  generated_id_lists = model.generate(input_ids.to(pt_device)).cpu().numpy().tolist()\n",
        "\n",
        "  # pad sequence.\n",
        "  generated_doc = []\n",
        "  for generated_ids in generated_id_lists:\n",
        "    missing_token = doc_cutoff - len(generated_ids)\n",
        "    generated_doc += [generated_ids + [0] * missing_token]\n",
        "\n",
        "  # we tried many other cleaner / faster solutions for merging existing and generated, but got none to work.\n",
        "  return [generated if original_string != \"\" else original_token\n",
        "          for generated, original_string, original_token\n",
        "          in zip(generated_doc, df[\"docstring\"].values, df[\"docstring_token\"].values)]\n",
        "\n",
        "pydf_train = batch_read_apply(\"python_data_train_initial.pkl\",\n",
        "                              train_size,\n",
        "                              batch_size=data_processing_batch_gpu,\n",
        "                              new_columns={\"docstring_token\": generate_docstrings})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY22Nzz9yGHd"
      },
      "source": [
        "## Save Train\n",
        "\n",
        "Shuffle and split train data for one-at-a-time loading later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_CrOjYayF2P"
      },
      "outputs": [],
      "source": [
        "shuffled_index = np.arange(len(pydf_train))\n",
        "rng.shuffle(shuffled_index)\n",
        "\n",
        "train_X = np.array(pydf_train[\"docstring_token\"].tolist())\n",
        "train_y = np.array(pydf_train[\"code_token\"].tolist())\n",
        "\n",
        "train_X = train_X[shuffled_index]\n",
        "train_y = train_y[shuffled_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoM5-S9CyhnS"
      },
      "outputs": [],
      "source": [
        "!mkdir train\n",
        "\n",
        "num_files = 5\n",
        "\n",
        "buffer_size = math.ceil(train_X.shape[0] / num_files)\n",
        "for buffer_start in range(0, train_X.shape[0], buffer_size):\n",
        "  buffer_end = min(buffer_start + buffer_size, train_X.shape[0])\n",
        "  buffer_train_X = train_X[buffer_start : buffer_end]\n",
        "  buffer_train_y = train_y[buffer_start : buffer_end]\n",
        "\n",
        "  with open(f\"train/python_data_train_{buffer_start:07d}_to_{buffer_end:07d}.pkl\", \"wb\") as f:\n",
        "    pickle.dump((buffer_train_X, buffer_train_y), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz5OKpgpdGkM",
        "outputId": "3c1603bf-9f57-4aa9-afa9-93bd14916704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: test/ (188 bytes security) (stored 0%)\n",
            "  adding: test/python_data_test.pkl (188 bytes security) (deflated 75%)\n",
            "  adding: valid/ (188 bytes security) (stored 0%)\n",
            "  adding: valid/python_data_validation.pkl (188 bytes security) (deflated 87%)\n",
            "  adding: train/ (188 bytes security) (stored 0%)\n",
            "  adding: train/python_data_train_0000000_to_0027049.pkl (188 bytes security) (deflated 88%)\n",
            "  adding: train/python_data_train_0027049_to_0054098.pkl (188 bytes security) (deflated 88%)\n",
            "  adding: train/python_data_train_0054098_to_0081147.pkl (188 bytes security) (deflated 88%)\n",
            "  adding: train/python_data_train_0081147_to_0108196.pkl (188 bytes security) (deflated 88%)\n",
            "  adding: train/python_data_train_0108196_to_0135242.pkl (188 bytes security) (deflated 88%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r python_data test valid train\n",
        "\n",
        "shutil.rmtree(\"test\")\n",
        "shutil.rmtree(\"valid\")\n",
        "os.remove(\"python_data_train_initial.pkl\")\n",
        "shutil.rmtree(\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69RwW0sCPZi6"
      },
      "outputs": [],
      "source": [
        "model.cpu()\n",
        "del model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOEnc-D63YrT"
      },
      "source": [
        "**checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK_-H2r9HOwz",
        "outputId": "96e67668-ea59-49d2-f667-0ea8f1f824df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57 minutes until here\n"
          ]
        }
      ],
      "source": [
        "elapsed_min = (time.time() - start_time) / 60\n",
        "print(f\"{elapsed_min:.0f} minutes until here\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZmZdganLRsH"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "for both approaches"
      ],
      "metadata": {
        "id": "Cv0mAyDwSpyI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bXzVuvfH1BVC"
      },
      "outputs": [],
      "source": [
        "starting_here = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y5IhUrDw1Feb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b8dc35-de36-4131-8ef7-3246b89aedbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Archive:  python_data.zip\n",
            "  inflating: python_data_test.pkl    \n",
            "   creating: valid/\n",
            "   creating: train/\n",
            "  inflating: train/python_data_train_0000000_to_0027049.pkl  \n",
            "  inflating: train/python_data_train_0027049_to_0054098.pkl  \n",
            "  inflating: train/python_data_train_0054098_to_0081147.pkl  \n",
            "  inflating: train/python_data_train_0081147_to_0108196.pkl  \n",
            "  inflating: train/python_data_train_0108196_to_0135242.pkl  \n",
            "  inflating: valid/python_data_validation.pkl  \n",
            "   creating: test/\n",
            "  inflating: test/python_data_test.pkl  \n"
          ]
        }
      ],
      "source": [
        "if starting_here:\n",
        "  vocab_size = 32100\n",
        "  train_size = 135242\n",
        "  val_size = 3385\n",
        "  code_cutoff = 100\n",
        "  doc_cutoff = 100\n",
        "\n",
        "  if not run_local:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !cp drive/MyDrive/python_data.zip python_data.zip\n",
        "    drive.flush_and_unmount()\n",
        "\n",
        "    !unzip python_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBg59G2imLmN"
      },
      "outputs": [],
      "source": [
        "class PyData(Sequence, Dataset):\n",
        "\n",
        "  def __init__(self, vocab_size, buffer_folder, batch_size, data_length, should_be_last=None):\n",
        "    self.vocab_size = vocab_size\n",
        "    self.buffer_folder = buffer_folder\n",
        "    self.batch_size = batch_size\n",
        "    self.data_length = data_length\n",
        "    self.files = os.listdir(buffer_folder)\n",
        "    self.id_current_file = 0\n",
        "    self.huggingface_format = False\n",
        "\n",
        "    # avoid getting the wrong file_length and make sure get_single_item doesnt\n",
        "    # run out of data in any but the last file (where the idx >= data_length protects it).\n",
        "    found_last = False\n",
        "    for file_id, file_name in enumerate(self.files):\n",
        "      if file_name == should_be_last:\n",
        "        # moves it to the end of the list.\n",
        "        self.files = self.files[:file_id] + self.files[file_id + 1:] + [self.files[file_id]]\n",
        "        found_last = True\n",
        "        break\n",
        "    if not found_last and should_be_last is not None:\n",
        "      raise ValueError(\"should_be_last was neither None nor presesnt in buffer_folder.\")\n",
        "    \n",
        "    self.load_current_file()\n",
        "    self.file_length = len(self.current_X)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return math.ceil(self.data_length / self.batch_size)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    tensorflow_format = self.getitem_tensorflow(idx)\n",
        "    if self.huggingface_format:\n",
        "      return {'input_ids': torch.LongTensor(tensorflow_format[0]).to(pt_device), \n",
        "              'attention_mask': torch.Tensor(self.attention_mask(tensorflow_format[0])).to(pt_device), \n",
        "              'labels': torch.LongTensor(tensorflow_format[1]).to(pt_device)}\n",
        "\n",
        "    else:\n",
        "      return tensorflow_format\n",
        "\n",
        "  def getitem_tensorflow(self, idx):\n",
        "    if isinstance(idx, int): \n",
        "      return self.get_single_batch(idx)\n",
        "    \n",
        "    elif isinstance(idx, slice):\n",
        "      if not (isinstance(idx.start, int) and\n",
        "              isinstance(idx.stop, int) and\n",
        "              (isinstance(idx.step, int) or idx.step is None )):\n",
        "        raise TypeError(\"Slice must use only int.\")\n",
        "      \n",
        "      X_list=[]\n",
        "      y_list=[]\n",
        "      \n",
        "      step_size = 1 if idx.step is None else idx.step \n",
        "\n",
        "      for i in range(idx.start, idx.stop, step_size):\n",
        "        example_X, example_y = self.get_single_batch(i)\n",
        "        X_list += [example_X]\n",
        "        y_list += [example_y]\n",
        "      \n",
        "      return np.vstack(X_list), np.vstack(y_list)\n",
        "    \n",
        "    else:\n",
        "      raise TypeError(\"Index type must be int or slice.\")\n",
        "  \n",
        "  def get_single_batch(self, idx):\n",
        "    X_list=[]\n",
        "    y_list=[]\n",
        "    for i in range(idx * self.batch_size, min((idx+1) * self.batch_size, self.data_length)):\n",
        "      example_X, example_y = self.get_single_item(i)\n",
        "      X_list += [example_X]\n",
        "      y_list += [example_y]\n",
        "    \n",
        "    # We would do padding here, if code_cutoff != doc_cutoff.\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "  def get_single_item(self, idx):\n",
        "    if idx < 0 or idx >= self.data_length:\n",
        "      raise IndexError(\"idx out of range.\")\n",
        "    \n",
        "    requested_file = idx // self.file_length\n",
        "    if requested_file != self.id_current_file:\n",
        "      self.id_current_file = requested_file\n",
        "      self.load_current_file()\n",
        "      \n",
        "    idx_in_file = idx % self.file_length\n",
        "    example_X, example_y = self.current_X[idx_in_file], self.current_y[idx_in_file]\n",
        "\n",
        "    return (example_X, self.onehot(example_y))\n",
        "\n",
        "  def onehot(self, example):\n",
        "    # Huggingface doesn't need onehot encoding.\n",
        "    if self.huggingface_format:\n",
        "      return example\n",
        "    encoded=np.zeros((len(example), self.vocab_size))\n",
        "    encoded[np.arange(len(example)), example]=1\n",
        "    return encoded\n",
        "  \n",
        "  def attention_mask(self, input_ids):\n",
        "    return (input_ids != 0).astype(float)\n",
        "\n",
        "  def load_current_file(self):\n",
        "    path = os.path.join(self.buffer_folder, self.files[self.id_current_file])\n",
        "    with open(path, 'rb') as f:\n",
        "      self.current_X, self.current_y = pickle.load(f) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pydata_validation = PyData(vocab_size, \"valid\", batch_size_tf, val_size)\n",
        "pydata_train = PyData(vocab_size, \"train\", batch_size_tf, train_size,\n",
        "                      should_be_last=\"python_data_train_0108196_to_0135242.pkl\") "
      ],
      "metadata": {
        "id": "IaW0L3tdSb0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuration for evaluation as well as training"
      ],
      "metadata": {
        "id": "VRLDg0KTfxX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vV3V2ZFt0ldm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly2GycUS0nBZ",
        "outputId": "f68c9108-2967-47e9-cc5a-438cc85d0f25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/tf_checkpoint.zip ./"
      ],
      "metadata": {
        "id": "hlbTc9KC0obv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/tf_checkpoint.zip"
      ],
      "metadata": {
        "id": "R_1y07wN0yNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/hf_checkpoint.zip ./"
      ],
      "metadata": {
        "id": "Y4djP_Zr1A71"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/hf_checkpoint.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWGUSQ8j1PKI",
        "outputId": "c4e2a638-66d7-41bb-f4c6-fb281e9dff7e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/hf_checkpoint.zip\n",
            "  inflating: after-225-epoch/config.json  \n",
            "  inflating: after-225-epoch/pytorch_model.bin  \n",
            "  inflating: after-225-epoch/training_args.bin  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_checkpoint_path = 'tf_checkpoint'\n",
        "ft_model_at = 'tf_checkpoint_24'\n",
        "\n",
        "hf_checkpoint_path = \"hf_checkpoint\"\n",
        "hf_model_at = os.path.join(hf_checkpoint_path, \"after-225-epoch\")"
      ],
      "metadata": {
        "id": "o9_qmUtefw0j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_model_at = \"after-225-epoch\""
      ],
      "metadata": {
        "id": "gkuksW6I1orC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM (Keras)\n",
        "We use the basic bi-LSTM architechture as introduced in the lecture. We decided to employ a 64 long embedding layer and just a single LSMT layer with 32 units to keep the complexity relatively low.\n",
        "\n",
        "For the implementation we used Keras as we had the most amount of experience with it."
      ],
      "metadata": {
        "id": "j2HrhSx-Sfkz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EU2GtwUhN6dY"
      },
      "outputs": [],
      "source": [
        "def create_lstm():\n",
        "  model = Sequential([Input(shape=(doc_cutoff,)),\n",
        "                      Embedding(vocab_size, 64, input_length=doc_cutoff),\n",
        "                      Bidirectional(LSTM(32, return_sequences=True)),\n",
        "                      TimeDistributed(Dense(vocab_size, activation='softmax'))])\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=1e-6)\n",
        "  model.compile(optimizer=optimizer, loss=keras.losses.CategoricalCrossentropy(), metrics=[\"acc\"])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_lstm()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE0XWQjrKmvz",
        "outputId": "698c915d-e954-4d58-d7f0-add909cd8471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 64)           2054400   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 100, 64)           24832     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 100, 32100)        2086500   \n",
            "=================================================================\n",
            "Total params: 4,165,732\n",
            "Trainable params: 4,165,732\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP7zKkR0YF_X"
      },
      "outputs": [],
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=ft_model_at\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2s3b8iIOKRJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "84888a75-3d0b-4750-9855-c10886c9d05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "5410/5410 [==============================] - 2017s 372ms/step - loss: 10.3709 - acc: 0.0044 - val_loss: 10.3396 - val_acc: 0.0649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/32\n",
            "5410/5410 [==============================] - 2024s 374ms/step - loss: 10.3034 - acc: 0.1883 - val_loss: 10.1316 - val_acc: 0.2111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/32\n",
            "5410/5410 [==============================] - 2050s 379ms/step - loss: 10.0012 - acc: 0.1395 - val_loss: 9.6930 - val_acc: 0.0154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/32\n",
            "5410/5410 [==============================] - 2158s 399ms/step - loss: 9.5371 - acc: 0.0103 - val_loss: 9.2263 - val_acc: 0.0104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/32\n",
            "5410/5410 [==============================] - 2226s 411ms/step - loss: 9.0687 - acc: 0.0100 - val_loss: 8.7717 - val_acc: 0.0101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/32\n",
            "5410/5410 [==============================] - 2241s 414ms/step - loss: 8.6191 - acc: 0.0100 - val_loss: 8.3285 - val_acc: 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/32\n",
            "5410/5410 [==============================] - 2238s 414ms/step - loss: 8.1782 - acc: 0.0100 - val_loss: 7.8910 - val_acc: 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/32\n",
            "5410/5410 [==============================] - 2239s 414ms/step - loss: 7.7442 - acc: 0.0100 - val_loss: 7.4686 - val_acc: 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/32\n",
            "5410/5410 [==============================] - 2232s 413ms/step - loss: 7.3279 - acc: 0.0112 - val_loss: 7.0694 - val_acc: 0.2591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/32\n",
            "5410/5410 [==============================] - 2229s 412ms/step - loss: 6.9378 - acc: 0.2732 - val_loss: 6.6999 - val_acc: 0.2978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/32\n",
            "5410/5410 [==============================] - 2262s 418ms/step - loss: 6.5792 - acc: 0.3002 - val_loss: 6.3644 - val_acc: 0.3166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/32\n",
            "5410/5410 [==============================] - 2255s 417ms/step - loss: 6.2539 - acc: 0.3154 - val_loss: 6.0657 - val_acc: 0.3359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/32\n",
            "5410/5410 [==============================] - 2231s 412ms/step - loss: 5.9688 - acc: 0.3310 - val_loss: 5.8062 - val_acc: 0.3359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/32\n",
            "5410/5410 [==============================] - 2266s 419ms/step - loss: 5.7227 - acc: 0.3305 - val_loss: 5.5842 - val_acc: 0.3359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/32\n",
            "5410/5410 [==============================] - 2286s 423ms/step - loss: 5.5110 - acc: 0.3312 - val_loss: 5.3969 - val_acc: 0.3359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/32\n",
            "5410/5410 [==============================] - 2227s 412ms/step - loss: 5.3334 - acc: 0.3310 - val_loss: 5.2397 - val_acc: 0.3359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: tf_checkpoint\\assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/32\n",
            "2602/5410 [=============>................] - ETA: 19:39 - loss: 5.1979 - acc: 0.3321"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-11-91c35057c796>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpydata_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(pydata_train, validation_data=pydata_validation, callbacks=[model_checkpoint_callback] , epochs=24)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT-BERT (🤗 Huggingface)"
      ],
      "metadata": {
        "id": "pQeOGNrgS4ZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🤗 Trainer optimization\n",
        "\n",
        "By default the 🤗 Trainer object keeps the predictions used for evaluation in one-hot format. That is not feasable on any of the machines we use for training.\n",
        "To reduce the memory usage we only evaluate on the most likely token at each position (less good than beam search)"
      ],
      "metadata": {
        "id": "zNw2y7BuPuA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainerWithAlteredEval(Trainer):\n",
        "    \"\"\"\n",
        "    Alters the evaluation / predicion loop behavior to reduce array size as suggested in\n",
        "    https://github.com/huggingface/transformers/issues/8476.\n",
        "    \"\"\"\n",
        "\n",
        "    def evaluation_loop(\n",
        "        self,\n",
        "        dataloader: DataLoader,\n",
        "        description: str,\n",
        "        prediction_loss_only: Optional[bool] = None,\n",
        "        ignore_keys: Optional[List[str]] = None,\n",
        "        metric_key_prefix: str = \"eval\",\n",
        "    ) -> EvalLoopOutput:\n",
        "        \"\"\"\n",
        "        Prediction/evaluation loop, shared by `Trainer.evaluate()` and `Trainer.predict()`.\n",
        "        Works both with or without labels.\n",
        "        \"\"\"\n",
        "        args = self.args\n",
        "\n",
        "        prediction_loss_only = prediction_loss_only if prediction_loss_only is not None else args.prediction_loss_only\n",
        "\n",
        "        # if eval is called w/o train init deepspeed here\n",
        "        if args.deepspeed and not self.deepspeed:\n",
        "\n",
        "            # XXX: eval doesn't have `resume_from_checkpoint` arg but we should be able to do eval\n",
        "            # from the checkpoint eventually\n",
        "            deepspeed_engine, _, _ = deepspeed_init(\n",
        "                self, num_training_steps=0, resume_from_checkpoint=None, inference=True\n",
        "            )\n",
        "            self.model = deepspeed_engine.module\n",
        "            self.model_wrapped = deepspeed_engine\n",
        "            self.deepspeed = deepspeed_engine\n",
        "\n",
        "        model = self._wrap_model(self.model, training=False)\n",
        "\n",
        "        # if full fp16 or bf16 eval is wanted and this ``evaluation`` or ``predict`` isn't called\n",
        "        # while ``train`` is running, cast it to the right dtype first and then put on device\n",
        "        if not self.is_in_train:\n",
        "            if args.fp16_full_eval:\n",
        "                model = model.to(dtype=torch.float16, device=args.device)\n",
        "            elif args.bf16_full_eval:\n",
        "                model = model.to(dtype=torch.bfloat16, device=args.device)\n",
        "\n",
        "        batch_size = dataloader.batch_size\n",
        "\n",
        "        #logger.info(f\"***** Running {description} *****\")\n",
        "        #if isinstance(dataloader.dataset, collections.abc.Sized):\n",
        "            #logger.info(f\"  Num examples = {self.num_examples(dataloader)}\")\n",
        "        #else:\n",
        "            #logger.info(\"  Num examples: Unknown\")\n",
        "        #logger.info(f\"  Batch size = {batch_size}\")\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        self.callback_handler.eval_dataloader = dataloader\n",
        "        # Do this before wrapping.\n",
        "        eval_dataset = dataloader.dataset\n",
        "\n",
        "        #if is_torch_tpu_available():\n",
        "        #    dataloader = pl.ParallelLoader(dataloader, [args.device]).per_device_loader(args.device)\n",
        "\n",
        "        if args.past_index >= 0:\n",
        "            self._past = None\n",
        "\n",
        "        # Initialize containers\n",
        "        # losses/preds/labels on GPU/TPU (accumulated for eval_accumulation_steps)\n",
        "        losses_host = None\n",
        "        preds_host = None\n",
        "        labels_host = None\n",
        "        # losses/preds/labels on CPU (final containers)\n",
        "        all_losses = None\n",
        "        all_preds = None\n",
        "        all_labels = None\n",
        "        # Will be useful when we have an iterable dataset so don't know its length.\n",
        "\n",
        "        observed_num_examples = 0\n",
        "        # Main evaluation loop\n",
        "        for step, inputs in enumerate(dataloader):\n",
        "            # Update the observed num examples\n",
        "            observed_batch_size = find_batch_size(inputs)\n",
        "            if observed_batch_size is not None:\n",
        "                observed_num_examples += observed_batch_size\n",
        "                # For batch samplers, batch_size is not known by the dataloader in advance.\n",
        "                if batch_size is None:\n",
        "                    batch_size = observed_batch_size\n",
        "\n",
        "            # Prediction step\n",
        "            loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)\n",
        "\n",
        "            # Update containers on host\n",
        "            if loss is not None:\n",
        "                losses = self._nested_gather(loss.repeat(batch_size))\n",
        "                losses_host = losses if losses_host is None else torch.cat((losses_host, losses), dim=0)\n",
        "            if logits is not None:\n",
        "                logits = self._pad_across_processes(logits)\n",
        "                logits = self._nested_gather(logits)\n",
        "                #preds_host = logits if preds_host is None else nested_concat(preds_host, logits, padding_index=-100)\n",
        "                # line above was changed to:\n",
        "                if isinstance(logits, tuple):\n",
        "                    logits_reduced = np.argmax(logits[0].cpu(), axis=-1)\n",
        "                else:\n",
        "                    logits_reduced = np.argmax(logits.cpu(), axis=-1)\n",
        "                preds_host = logits_reduced if preds_host is None else nested_concat(preds_host, logits_reduced, padding_index=-100)\n",
        "            if labels is not None:\n",
        "                labels = self._pad_across_processes(labels)\n",
        "                labels = self._nested_gather(labels)\n",
        "                labels_host = labels if labels_host is None else nested_concat(labels_host, labels, padding_index=-100)\n",
        "            self.control = self.callback_handler.on_prediction_step(args, self.state, self.control)\n",
        "\n",
        "            # Gather all tensors and put them back on the CPU if we have done enough accumulation steps.\n",
        "            if args.eval_accumulation_steps is not None and (step + 1) % args.eval_accumulation_steps == 0:\n",
        "                if losses_host is not None:\n",
        "                    losses = nested_numpify(losses_host)\n",
        "                    all_losses = losses if all_losses is None else np.concatenate((all_losses, losses), axis=0)\n",
        "                if preds_host is not None:\n",
        "                    logits = nested_numpify(preds_host)\n",
        "                    all_preds = logits if all_preds is None else nested_concat(all_preds, logits, padding_index=-100)\n",
        "                if labels_host is not None:\n",
        "                    labels = nested_numpify(labels_host)\n",
        "                    all_labels = (\n",
        "                        labels if all_labels is None else nested_concat(all_labels, labels, padding_index=-100)\n",
        "                    )\n",
        "\n",
        "                # Set back to None to begin a new accumulation\n",
        "                losses_host, preds_host, labels_host = None, None, None\n",
        "\n",
        "        if args.past_index and hasattr(self, \"_past\"):\n",
        "            # Clean the state at the end of the evaluation loop\n",
        "            delattr(self, \"_past\")\n",
        "\n",
        "        # Gather all remaining tensors and put them back on the CPU\n",
        "        if losses_host is not None:\n",
        "            losses = nested_numpify(losses_host)\n",
        "            all_losses = losses if all_losses is None else np.concatenate((all_losses, losses), axis=0)\n",
        "        if preds_host is not None:\n",
        "            logits = nested_numpify(preds_host)\n",
        "            all_preds = logits if all_preds is None else nested_concat(all_preds, logits, padding_index=-100)\n",
        "        if labels_host is not None:\n",
        "            labels = nested_numpify(labels_host)\n",
        "            all_labels = labels if all_labels is None else nested_concat(all_labels, labels, padding_index=-100)\n",
        "\n",
        "        # Number of samples\n",
        "        if not isinstance(eval_dataset, IterableDataset):\n",
        "            num_samples = len(eval_dataset)\n",
        "        # The instance check is weird and does not actually check for the type, but whether the dataset has the right\n",
        "        # methods. Therefore we need to make sure it also has the attribute.\n",
        "        elif isinstance(eval_dataset, IterableDatasetShard) and hasattr(eval_dataset, \"num_examples\"):\n",
        "            num_samples = eval_dataset.num_examples\n",
        "        else:\n",
        "            num_samples = observed_num_examples\n",
        "\n",
        "        # Number of losses has been rounded to a multiple of batch_size and in a distributed training, the number of\n",
        "        # samplers has been rounded to a multiple of batch_size, so we truncate.\n",
        "        if all_losses is not None:\n",
        "            all_losses = all_losses[:num_samples]\n",
        "        if all_preds is not None:\n",
        "            all_preds = nested_truncate(all_preds, num_samples)\n",
        "        if all_labels is not None:\n",
        "            all_labels = nested_truncate(all_labels, num_samples)\n",
        "\n",
        "        # Metrics!\n",
        "        if self.compute_metrics is not None and all_preds is not None and all_labels is not None:\n",
        "            metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))\n",
        "        else:\n",
        "            metrics = {}\n",
        "\n",
        "        # To be JSON-serializable, we need to remove numpy types or zero-d tensors\n",
        "        metrics = denumpify_detensorize(metrics)\n",
        "\n",
        "        if all_losses is not None:\n",
        "            metrics[f\"{metric_key_prefix}_loss\"] = all_losses.mean().item()\n",
        "\n",
        "        # Prefix all keys with metric_key_prefix + '_'\n",
        "        for key in list(metrics.keys()):\n",
        "            if not key.startswith(f\"{metric_key_prefix}_\"):\n",
        "                metrics[f\"{metric_key_prefix}_{key}\"] = metrics.pop(key)\n",
        "\n",
        "        return EvalLoopOutput(predictions=all_preds, label_ids=all_labels, metrics=metrics, num_samples=num_samples)\n",
        "    \n",
        "    def prediction_loop(\n",
        "        self,\n",
        "        dataloader: DataLoader,\n",
        "        description: str,\n",
        "        prediction_loss_only: Optional[bool] = None,\n",
        "        ignore_keys: Optional[List[str]] = None,\n",
        "        metric_key_prefix: str = \"eval\",\n",
        "    ) -> PredictionOutput:\n",
        "        \"\"\"\n",
        "        Prediction/evaluation loop, shared by `Trainer.evaluate()` and `Trainer.predict()`.\n",
        "        Works both with or without labels.\n",
        "        \"\"\"\n",
        "        args = self.args\n",
        "\n",
        "        if not isinstance(dataloader.dataset, collections.abc.Sized):\n",
        "            raise ValueError(\"dataset must implement __len__\")\n",
        "        prediction_loss_only = prediction_loss_only if prediction_loss_only is not None else args.prediction_loss_only\n",
        "\n",
        "        # if eval is called w/o train init deepspeed here\n",
        "        if args.deepspeed and not self.deepspeed:\n",
        "\n",
        "            # XXX: eval doesn't have `resume_from_checkpoint` arg but we should be able to do eval\n",
        "            # from the checkpoint eventually\n",
        "            deepspeed_engine, _, _ = deepspeed_init(self, num_training_steps=0, resume_from_checkpoint=None)\n",
        "            self.model = deepspeed_engine.module\n",
        "            self.model_wrapped = deepspeed_engine\n",
        "            self.deepspeed = deepspeed_engine\n",
        "            # XXX: we don't need optim/sched for inference, but this needs to be sorted out, since\n",
        "            # for example the Z3-optimizer is a must for zero3 to work even for inference - what we\n",
        "            # don't need is the deepspeed basic optimizer which is self.optimizer.optimizer\n",
        "            deepspeed_engine.optimizer.optimizer = None\n",
        "            deepspeed_engine.lr_scheduler = None\n",
        "\n",
        "        model = self._wrap_model(self.model, training=False)\n",
        "\n",
        "        # if full fp16 or bf16 eval is wanted and this ``evaluation`` or ``predict`` isn't called\n",
        "        # while ``train`` is running, cast it to the right dtype first and then put on device\n",
        "        if not self.is_in_train:\n",
        "            if args.fp16_full_eval:\n",
        "                model = model.to(dtype=torch.float16, device=args.device)\n",
        "            elif args.bf16_full_eval:\n",
        "                model = model.to(dtype=torch.bfloat16, device=args.device)\n",
        "\n",
        "        batch_size = dataloader.batch_size\n",
        "        num_examples = self.num_examples(dataloader)\n",
        "        #logger.info(f\"***** Running {description} *****\")\n",
        "        #logger.info(f\"  Num examples = {num_examples}\")\n",
        "        #logger.info(f\"  Batch size = {batch_size}\")\n",
        "        losses_host: torch.Tensor = None\n",
        "        preds_host: Union[torch.Tensor, List[torch.Tensor]] = None\n",
        "        labels_host: Union[torch.Tensor, List[torch.Tensor]] = None\n",
        "\n",
        "        world_size = max(1, args.world_size)\n",
        "\n",
        "        eval_losses_gatherer = DistributedTensorGatherer(world_size, num_examples, make_multiple_of=batch_size)\n",
        "        if not prediction_loss_only:\n",
        "            # The actual number of eval_sample can be greater than num_examples in distributed settings (when we pass\n",
        "            # a batch size to the sampler)\n",
        "            make_multiple_of = None\n",
        "            if hasattr(dataloader, \"sampler\") and isinstance(dataloader.sampler, SequentialDistributedSampler):\n",
        "                make_multiple_of = dataloader.sampler.batch_size\n",
        "            preds_gatherer = DistributedTensorGatherer(world_size, num_examples, make_multiple_of=make_multiple_of)\n",
        "            labels_gatherer = DistributedTensorGatherer(world_size, num_examples, make_multiple_of=make_multiple_of)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        #if is_torch_tpu_available():\n",
        "        #    dataloader = pl.ParallelLoader(dataloader, [args.device]).per_device_loader(args.device)\n",
        "\n",
        "        if args.past_index >= 0:\n",
        "            self._past = None\n",
        "\n",
        "        self.callback_handler.eval_dataloader = dataloader\n",
        "\n",
        "        for step, inputs in enumerate(dataloader):\n",
        "            loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)\n",
        "            if loss is not None:\n",
        "                losses = loss.repeat(batch_size)\n",
        "                losses_host = losses if losses_host is None else torch.cat((losses_host, losses), dim=0)\n",
        "            if logits is not None:\n",
        "                #preds_host = logits if preds_host is None else nested_concat(preds_host, logits, padding_index=-100)\n",
        "                # line above was changed to:\n",
        "                if isinstance(logits, tuple):\n",
        "                    logits_reduced = np.argmax(logits[0].cpu(), axis=-1)\n",
        "                else:\n",
        "                    logits_reduced = np.argmax(logits.cpu(), axis=-1)\n",
        "                preds_host = logits_reduced if preds_host is None else nested_concat(preds_host, logits_reduced, padding_index=-100)\n",
        "            if labels is not None:\n",
        "                labels_host = labels if labels_host is None else nested_concat(labels_host, labels, padding_index=-100)\n",
        "            self.control = self.callback_handler.on_prediction_step(args, self.state, self.control)\n",
        "\n",
        "            # Gather all tensors and put them back on the CPU if we have done enough accumulation steps.\n",
        "            if args.eval_accumulation_steps is not None and (step + 1) % args.eval_accumulation_steps == 0:\n",
        "                eval_losses_gatherer.add_arrays(self._gather_and_numpify(losses_host, \"eval_losses\"))\n",
        "                if not prediction_loss_only:\n",
        "                    preds_gatherer.add_arrays(self._gather_and_numpify(preds_host, \"eval_preds\"))\n",
        "                    labels_gatherer.add_arrays(self._gather_and_numpify(labels_host, \"eval_label_ids\"))\n",
        "\n",
        "                # Set back to None to begin a new accumulation\n",
        "                losses_host, preds_host, labels_host = None, None, None\n",
        "\n",
        "        if args.past_index and hasattr(self, \"_past\"):\n",
        "            # Clean the state at the end of the evaluation loop\n",
        "            delattr(self, \"_past\")\n",
        "\n",
        "        # Gather all remaining tensors and put them back on the CPU\n",
        "        eval_losses_gatherer.add_arrays(self._gather_and_numpify(losses_host, \"eval_losses\"))\n",
        "        if not prediction_loss_only:\n",
        "            preds_gatherer.add_arrays(self._gather_and_numpify(preds_host, \"eval_preds\"))\n",
        "            labels_gatherer.add_arrays(self._gather_and_numpify(labels_host, \"eval_label_ids\"))\n",
        "\n",
        "        eval_loss = eval_losses_gatherer.finalize()\n",
        "        preds = preds_gatherer.finalize() if not prediction_loss_only else None\n",
        "        label_ids = labels_gatherer.finalize() if not prediction_loss_only else None\n",
        "\n",
        "        if self.compute_metrics is not None and preds is not None and label_ids is not None:\n",
        "            metrics = self.compute_metrics(EvalPrediction(predictions=preds, label_ids=label_ids))\n",
        "        else:\n",
        "            metrics = {}\n",
        "\n",
        "        # To be JSON-serializable, we need to remove numpy types or zero-d tensors\n",
        "        metrics = denumpify_detensorize(metrics)\n",
        "\n",
        "        if eval_loss is not None:\n",
        "            metrics[f\"{metric_key_prefix}_loss\"] = eval_loss.mean().item()\n",
        "\n",
        "        # Prefix all keys with metric_key_prefix + '_'\n",
        "        for key in list(metrics.keys()):\n",
        "            if not key.startswith(f\"{metric_key_prefix}_\"):\n",
        "                metrics[f\"{metric_key_prefix}_{key}\"] = metrics.pop(key)\n",
        "\n",
        "        return PredictionOutput(predictions=preds, label_ids=label_ids, metrics=metrics)"
      ],
      "metadata": {
        "id": "Pxs6dpGbP0QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "UbsGhrmvS9ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if starting_here:\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base-multi-sum\")\n",
        "\n",
        "prajjwal1_bert_small_param = {\n",
        "  \"_name_or_path\": \"custom-bert-small\",\n",
        "  \"attention_probs_dropout_prob\": 0.1,\n",
        "  \"bos_token_id\": tokenizer.bos_token_id,\n",
        "  \"eos_token_id\": tokenizer.eos_token_id,\n",
        "  \"hidden_act\": \"gelu\",\n",
        "  \"hidden_dropout_prob\": 0.1,\n",
        "  \"hidden_size\": 512,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"intermediate_size\": 2048,\n",
        "  \"layer_norm_eps\": 1e-12,\n",
        "  \"max_position_embeddings\": 512,\n",
        "  \"model_type\": \"bert\",\n",
        "  \"num_attention_heads\": 8,\n",
        "  \"num_hidden_layers\": 4,\n",
        "  \"pad_token_id\": tokenizer.pad_token_id,\n",
        "  \"position_embedding_type\": \"absolute\",\n",
        "  \"sep_token_id\": tokenizer.sep_token_id,\n",
        "  \"type_vocab_size\": 2,\n",
        "  \"use_cache\": True,\n",
        "  \"vocab_size\": tokenizer.vocab_size\n",
        "}"
      ],
      "metadata": {
        "id": "v4hXfeGOTVCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_encoder = BertConfig(**prajjwal1_bert_small_param)\n",
        "config_decoder = BertConfig(**prajjwal1_bert_small_param)\n",
        "\n",
        "config = EncoderDecoderConfig.from_encoder_decoder_configs(config_encoder, config_decoder)\n",
        "config.decoder_start_token_id = tokenizer.bos_token_id\n",
        "\n",
        "model = EncoderDecoderModel(config=config).to(pt_device)\n",
        "\n",
        "config_encoder = model.config.encoder\n",
        "config_decoder = model.config.decoder\n",
        "config_decoder.is_decoder = True\n",
        "config_decoder.add_cross_attention = True\n",
        "\n",
        "# These values seem to not be set in the constructor.\n",
        "for config_to_adjust in (config, config_encoder, config_decoder):\n",
        "  config_to_adjust.vocab_size = tokenizer.vocab_size\n",
        "  config_to_adjust.bos_token_id = tokenizer.bos_token_id\n",
        "  config_to_adjust.eos_token_id = tokenizer.eos_token_id\n",
        "  config_to_adjust.pad_token_id = tokenizer.pad_token_id\n",
        "  config_to_adjust.sep_token_id = tokenizer.sep_token_id"
      ],
      "metadata": {
        "id": "uO5rhiK7RXXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pydata_validation.huggingface_format = True\n",
        "pydata_train.huggingface_format = True"
      ],
      "metadata": {
        "id": "pYsW9TfZT9t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some very simple metrics that we can implement ourselfs."
      ],
      "metadata": {
        "id": "tev8A1B5UEyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "problematic_token = tokenizer(\"def(,_\\n ( , _ \\n\")['input_ids'] + [0]\n",
        "\n",
        "def can_complie(source_code_token):\n",
        "  source_code = tokenizer.decode(source_code_token, skip_special_tokens=True)\n",
        "  valid = True\n",
        "\n",
        "  try:\n",
        "    ast.parse(source_code)\n",
        "  except SyntaxError:\n",
        "    valid = False\n",
        "  \n",
        "  return valid\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  simple_accs, problematics, matches, complies = [], [], [], []\n",
        "\n",
        "  for prediction, label in zip(predictions, labels):\n",
        "    # list of correct / not correct prediction (incl. padding), becomes percentage in return.\n",
        "    simple_accs += [(prediction == label).astype(int)]\n",
        "    # with higher learning rates the model learned to reproduce the most frequent\n",
        "    # tokens. This serves as an indicator for us, whether this is currently happening.\n",
        "    problematics += [sum(np.count_nonzero(prediction == token) / prediction.size\n",
        "                     for token in problematic_token)]\n",
        "    # for accuracy using a whole function as the smallest unit. Stayed 0 in the whole\n",
        "    # training. The missing beam search also did not help.\n",
        "    matches += [1 if np.all(prediction == label) else 0]\n",
        "    # for percent of eval dataset that could run as python code. Also stayed 0, because\n",
        "    # of missing beam search. The examples generated using beamsearch largely compiled.\n",
        "    complies += [1 if can_complie(prediction) else 0]\n",
        "  \n",
        "  return {\"simple_acc\": np.mean(simple_accs),\n",
        "          \"exact_match\": np.mean(matches),\n",
        "          \"problem_token_perc\": np.mean(problematics),\n",
        "          \"num_compling\": np.sum(complies),\n",
        "          \"compling_perc\": np.mean(complies)}"
      ],
      "metadata": {
        "id": "CoEv8YJxUEYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=hf_checkpoint_path,\n",
        "    save_total_limit=1,\n",
        "    num_train_epochs=225,\n",
        "    per_device_train_batch_size=1, # batch size must stay 1, because of our implementation\n",
        "    gradient_accumulation_steps=10,# this puts the effective batch size at 10 * 25 = 250\n",
        "    warmup_steps=1000,\n",
        "    learning_rate=0.000002,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_steps=1000,\n",
        "    logging_steps=100,\n",
        "    logging_first_step=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    eval_accumulation_steps=10,\n",
        "    per_device_eval_batch_size=1,\n",
        "    dataloader_pin_memory = False  # for us this fixes an error during the training\n",
        ") \n",
        "\n",
        "trainer = TrainerWithAlteredEval(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=pydata_train,\n",
        "    eval_dataset=pydata_validation,\n",
        "    data_collator=lambda x:x[0],   # like the batchsize this is neede bacuase of our implementation\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "jFzTwrtJUReL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695fa7a4-4845-4324-a13a-1e4f9645d345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "8dTO1DtjWAgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "qGS9U5LQgpJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data / models"
      ],
      "metadata": {
        "id": "_N_wrCqT7pVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_folder = \"evaluation-results\"\n",
        "evaluation_for_model_at = hf_model_at\n",
        "\n",
        "hf_model = AutoModelForSeq2SeqLM.from_pretrained(hf_model_at).to(pt_device)\n",
        "tf_model = create_lstm()\n",
        "tf_model.load_weights('tf_checkpoint_24/')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-base-multi-sum\")\n",
        "\n",
        "with open('test/python_data_test.pkl', 'rb') as f:\n",
        "  pydata_test_X, pydata_test_y = pickle.load(f)"
      ],
      "metadata": {
        "id": "jMGhcg8y7trJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "ca72b1470f184a1288adfd3eaf68610e",
            "5f0c16bd0a44473e9b8561d27cf3e623",
            "17af834fa7ca40bd9452ea139f0cd0fe",
            "6bca81c45fbf4220b26b2490222a6ded",
            "0dd39a245f6b4ca883b05f818eee919e",
            "c189046508be4d799c439e2e3026f799",
            "8232891ef1c94430adb0e7689788359d",
            "bf73d9a8de0448bf9cfb8eaa0398562d",
            "41f03f0390dd4eaaba69186f5f2e0c1a",
            "57b2535f1e044dfcad1e3dbd1811c1c5",
            "651ab12d48e341e0960bc8ab0c63468c",
            "c1a3b9edaca14666860199facd097347",
            "022f6111247546e1b10e3c28d2e6e9e3",
            "a42bb42e0bff4fed9ed637c020fbe134",
            "bb0f45fdd51e4cb98e5507c187d3dc92",
            "29ac15966a1341808dce4a52996b9b32",
            "d05a275fae7b427497c08fb38230bf44",
            "230080fd79f845ccb1e4661a0b49cb7b",
            "f28bec277082490db270f3a894fbf0d0",
            "1f9df55093c84cc19eb1f309fb5c954b",
            "34e95ef9ece749e589172cccf1a66931",
            "fdc69b5d83074da5859c85abf8f8b6ac",
            "6bee4ce967f94caaa2d461fc9709ea4a",
            "2e8b6f3006b04f6fa9784e595da94812",
            "9692bf0ce8bf42e096def24a4ceb08cb",
            "ed6c255cb85e403799faa1bdd9faed94",
            "4183e0ac8a9d4c55b4613c37279392a1",
            "7a488478f5154f1e985e48734111b8bf",
            "a6e84c63aa7b436dbf21cc805a111909",
            "2508278550e4457786f2c268e350b009",
            "9a51a17185384310beaf339fdb67efe9",
            "fefd294b3e6f46b8a7cf1dce91492f6b",
            "06bdc69d24f24fcd849e4e216cd272b6",
            "9a5c3d42fdb1412b818d90f68128d70c",
            "e87c950a5d4a46e9bddcee6866dbb560",
            "50200253fd334a1ca96d636c4cb9b881",
            "85578ef21db446c2968186ffefa2ae43",
            "ff3d2e9b8b4d465fbcf4f168ac829320",
            "72f48ac771a14ed5949ef0a531640a78",
            "f9be53da116342c98490d44478eff591",
            "1ec6c98646cb434da66cb613ba2968b5",
            "40a0e1bdb6dd41e89a6541c8bf4626c3",
            "153807c8e30a49f7aee1b0383f310d4e",
            "dfad3bebb97a47d5a64f0fe8b3d6a190",
            "25b3271a42274ca7a5fe27d7053b7520",
            "39e2d974520941879d37334c8ffc015b",
            "3dc048aaba92485aa56e6926ec69e50c",
            "c012e2452460478e99224db36beada18",
            "16c470a1b29447449333a84992c05573",
            "8888640b6a3340d7a1c2ce95d8f28f53",
            "bababe73d896484b860ca8b5cc348fea",
            "f30e5a2070ac49288cdd4cf1c9f24a65",
            "7fcb60c8fecb415f9c18199b69f21ed9",
            "9c84e7286d5e4e3a93ba38a63d6d16d6",
            "b1d6f997d4ca49a899a58e3da6d987a1"
          ]
        },
        "outputId": "d7c0cfc6-d1d8-4179-9661-1351e7733060"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca72b1470f184a1288adfd3eaf68610e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1a3b9edaca14666860199facd097347",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/687k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bee4ce967f94caaa2d461fc9709ea4a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/287k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a5c3d42fdb1412b818d90f68128d70c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25b3271a42274ca7a5fe27d7053b7520",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/12.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_test = []\n",
        "results_user = []\n",
        "\n",
        "for (dirpath, dirnames, filenames) in os.walk(evaluation_folder):\n",
        "  for filename in filenames:\n",
        "    with open(os.path.join(dirpath, filename), 'rb') as f:\n",
        "      result = eval(f.read())\n",
        "\n",
        "      results_test += result[:10]\n",
        "      results_user += result[10:]\n",
        "\n",
        "results_test = pd.DataFrame(results_test)\n",
        "results_user = pd.DataFrame(results_user)[[1, 2, 3, 4]]"
      ],
      "metadata": {
        "id": "_ZcbZjuk8Dho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_test.columns = [\"id in dataset\", \"code quality\", \"fitting docstring\"]\n",
        "results_test[\"id in dataset\"] = results_test[\"id in dataset\"].apply(lambda id: id[5:])\n",
        "\n",
        "results_user.columns = [\"code quality\", \"fitting docstring\", \"docstring_token\", \"code_token\"]"
      ],
      "metadata": {
        "id": "u0_X06bp9Bag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Datapoints for Testset:                {len(results_test):3.0f} \"\n",
        "      f\"(10 questions x {len(results_test) // 10} participants)\")\n",
        "print(f\"Datapoints for user chosen docstring: {len(results_user):3.0f} \"\n",
        "      f\"( 5 questions x {len(results_user) // 5} participants)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDqSyPFOJykh",
        "outputId": "780f9e9a-5e98-45b9-febe-fe65ea169956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datapoints for Testset:                120 (10 questions x 12 participants)\n",
            "Datapoints for user choosen docstring:  60 ( 5 questions x 12 participants)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GGlhP3yh-BLB",
        "outputId": "41cdec39-fc36-4543-fdd7-1cfd8f4c3faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  id in dataset  code quality  fitting docstring\n",
              "0         18695             3                  1\n",
              "1         17178             3                  1\n",
              "2          9730             1                  1\n",
              "3          3827             1                  1\n",
              "4         12568             1                  1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id in dataset</th>\n",
              "      <th>code quality</th>\n",
              "      <th>fitting docstring</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18695</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17178</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9730</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3827</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12568</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_user.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BHPMRhfp-Cmo",
        "outputId": "6032dc03-6a53-47f5-d392-d6bd13abc365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   code quality  fitting docstring  \\\n",
              "0             3                  2   \n",
              "1             3                  3   \n",
              "2             2                  1   \n",
              "3             1                  1   \n",
              "4             3                  4   \n",
              "\n",
              "                              docstring_token  \\\n",
              "0   [1, 7018, 326, 769, 434, 392, 526, 18, 2]   \n",
              "1  [1, 1564, 309, 460, 353, 392, 2144, 18, 2]   \n",
              "2           [1, 30296, 434, 2795, 924, 18, 2]   \n",
              "3        [1, 990, 1122, 930, 434, 526, 18, 2]   \n",
              "4                       [1, 1684, 526, 18, 2]   \n",
              "\n",
              "                                          code_token  \n",
              "0  [1, 1, 536, 769, 67, 2469, 12, 1126, 4672, 203...  \n",
              "1  [1, 1, 536, 353, 67, 1132, 12, 1132, 4672, 203...  \n",
              "2  [1, 1, 536, 336, 67, 1132, 12, 1132, 21, 16, 4...  \n",
              "3  [1, 1, 536, 1122, 67, 2956, 12, 1132, 4672, 20...  \n",
              "4  [1, 1, 536, 526, 67, 1126, 12, 1132, 4672, 203...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code quality</th>\n",
              "      <th>fitting docstring</th>\n",
              "      <th>docstring_token</th>\n",
              "      <th>code_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>[1, 7018, 326, 769, 434, 392, 526, 18, 2]</td>\n",
              "      <td>[1, 1, 536, 769, 67, 2469, 12, 1126, 4672, 203...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[1, 1564, 309, 460, 353, 392, 2144, 18, 2]</td>\n",
              "      <td>[1, 1, 536, 353, 67, 1132, 12, 1132, 4672, 203...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 30296, 434, 2795, 924, 18, 2]</td>\n",
              "      <td>[1, 1, 536, 336, 67, 1132, 12, 1132, 21, 16, 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 990, 1122, 930, 434, 526, 18, 2]</td>\n",
              "      <td>[1, 1, 536, 1122, 67, 2956, 12, 1132, 4672, 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>[1, 1684, 526, 18, 2]</td>\n",
              "      <td>[1, 1, 536, 526, 67, 1126, 12, 1132, 4672, 203...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "RXDm6MJZJU_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_manual(evaluation_test, evaluation_user):\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "  test_code_x = np.array(evaluation_test[\"code quality\"].value_counts().sort_index().keys())\n",
        "  test_code_y = np.array(evaluation_test[\"code quality\"].value_counts().sort_index().values)\n",
        "  user_code_x = np.array(evaluation_user[\"code quality\"].value_counts().sort_index().keys())\n",
        "  user_code_y = np.array(evaluation_user[\"code quality\"].value_counts().sort_index().values)\n",
        "\n",
        "  ax1.bar(test_code_x - 0.15, 100 * test_code_y / len(evaluation_test), width=0.3, label=\"testdata\")\n",
        "  ax1.bar(user_code_x + 0.15, 100 * user_code_y / len(evaluation_user), width=0.3, label=\"user give docstring\")\n",
        "  ax1.set_ylabel(\"% votes\")\n",
        "  ax1.set_xlabel(\"rating\")\n",
        "  ax1.set_title(\"How would you rate the code quality?\")\n",
        "  ax1.legend()\n",
        "  ax1.grid()\n",
        "\n",
        "  test_doc_x = np.array(evaluation_test[\"fitting docstring\"].value_counts().sort_index().keys())\n",
        "  test_doc_y = np.array(evaluation_test[\"fitting docstring\"].value_counts().sort_index().values)\n",
        "  user_doc_x = np.array(evaluation_user[\"fitting docstring\"].value_counts().sort_index().keys())\n",
        "  user_doc_y = np.array(evaluation_user[\"fitting docstring\"].value_counts().sort_index().values)\n",
        "\n",
        "  ax2.bar(test_doc_x - 0.15, 100 * test_doc_y / len(evaluation_test), width=0.3, label=\"testdata\")\n",
        "  ax2.bar(user_doc_x + 0.15, 100 * user_doc_y / len(evaluation_user), width=0.3, label=\"user give docstring\")\n",
        "  ax2.set_ylabel(\"% votes\")\n",
        "  ax2.set_xlabel(\"rating\")\n",
        "  ax2.set_title(\"How well does the code fit the given docstring?\")\n",
        "  ax2.legend()\n",
        "  ax2.grid()"
      ],
      "metadata": {
        "id": "KcQ6fZvzAx27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hf_code(input_ids_batch):\n",
        "  generated = hf_model.generate(torch.LongTensor(input_ids_batch).to(pt_device),\n",
        "                                max_length=150,\n",
        "                                num_beams=5,\n",
        "                                repetition_penalty=1.4,\n",
        "                                no_repeat_ngram_size=4\n",
        "                                )\n",
        "\n",
        "  return tokenizer.batch_decode(generated, skip_special_tokens=True), generated\n",
        "\n",
        "def get_tf_code(input_ids_batch):\n",
        "  generated = tf_model.predict(input_ids_batch)\n",
        "  token_ids = np.argmax(generated, axis=1)\n",
        "  \n",
        "  return tokenizer.batch_decode(token_ids, skip_special_tokens=True), token_ids\n",
        "\n",
        "def get_test_outputs(test_X, test_y):\n",
        "  \n",
        "  outputs = {}\n",
        "\n",
        "  for model_name, model_predict in [(\"Transformer\", get_hf_code), (\"LSTM\", get_tf_code)]:\n",
        "    string_outputs, token_outputs = [], []\n",
        "\n",
        "    for batch_start in tqdm(range(0, len(test_X), data_processing_batch_gpu)):\n",
        "      \n",
        "      batch = test_X[batch_start : batch_start + data_processing_batch_gpu]\n",
        "      batch = [example[:100] + [0] * (100 - len(example)) for example in batch]\n",
        "      string_output, token_output = model_predict(np.array(batch))\n",
        "      string_outputs += [string_output]\n",
        "      token_outputs += [token_output]\n",
        "    \n",
        "    outputs[model_name] = (string_outputs, token_outputs)\n",
        "  return outputs    "
      ],
      "metadata": {
        "id": "t1SQJC1wLGsj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_outputs = get_test_outputs(pydata_test_X, pydata_test_y)\n",
        "with open('test/python_data_test_model_generated.pkl', 'wb') as f:\n",
        "  pickle.dump(model_outputs, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-U8XMYeZoQK",
        "outputId": "047ecf53-30c2-47fd-c35d-a4bbff495a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 222/222 [1:41:05<00:00, 27.32s/it]\n",
            "100%|██████████| 222/222 [09:15<00:00,  2.50s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test/python_data_test_model_generated.pkl', 'rb') as f:\n",
        "  model_outputs = pickle.load(f)"
      ],
      "metadata": {
        "id": "QweKA4guqEp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4-0VpraAqaB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test/python_data_test_model_generated.pkl', 'rb') as f:\n",
        "  model_outputs = pickle.load(f)\n",
        "\n",
        "model_outputs[\"LSTM\"] = ([\"\".join(output) for output in model_outputs[\"LSTM\"][0]],\n",
        "                         np.array(model_outputs[\"LSTM\"][1]))\n",
        "model_outputs[\"Transformer\"] = ([\"\".join(output) for output in model_outputs[\"Transformer\"][0]],\n",
        "                                np.array([tensor.cpu().numpy().tolist()[:100] + [0] * (100 - len(tensor))\n",
        "                                          for tensor in model_outputs[\"Transformer\"][1]]))\n",
        "correct_outputs = np.array([example[:100] + [0] * (100 - len(example)) for example in pydata_test_y])"
      ],
      "metadata": {
        "id": "ZH7_ChAr3RL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_outputs[\"LSTM\"][1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khv6uGpGpEzH",
        "outputId": "367c303f-3089-4455-d35b-0255d292ebef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(222, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_metrics((model_outputs[\"LSTM\"][1], correct_outputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXHfcGX0l2NA",
        "outputId": "5498e2da-7aad-43ab-81b8-d0ba4bbaa301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'simple_acc': 0.026801801801801802,\n",
              " 'exact_match': 0.0,\n",
              " 'problem_token_perc': 0.9808558558558561,\n",
              " 'num_compling': 0,\n",
              " 'compling_perc': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Evaluation"
      ],
      "metadata": {
        "id": "x64PzyCcJYoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_manual(results_test, results_user)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Yhmano8OBH66",
        "outputId": "e109b250-248f-477b-ece2-1a8a03e13317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VoOZ-_zGK1a9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Yaoq7L4W7zCH",
        "zNw2y7BuPuA9"
      ],
      "name": "NLPP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ca72b1470f184a1288adfd3eaf68610e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5f0c16bd0a44473e9b8561d27cf3e623",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_17af834fa7ca40bd9452ea139f0cd0fe",
              "IPY_MODEL_6bca81c45fbf4220b26b2490222a6ded",
              "IPY_MODEL_0dd39a245f6b4ca883b05f818eee919e"
            ]
          }
        },
        "5f0c16bd0a44473e9b8561d27cf3e623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17af834fa7ca40bd9452ea139f0cd0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c189046508be4d799c439e2e3026f799",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8232891ef1c94430adb0e7689788359d"
          }
        },
        "6bca81c45fbf4220b26b2490222a6ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf73d9a8de0448bf9cfb8eaa0398562d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1477,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1477,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41f03f0390dd4eaaba69186f5f2e0c1a"
          }
        },
        "0dd39a245f6b4ca883b05f818eee919e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_57b2535f1e044dfcad1e3dbd1811c1c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.44k/1.44k [00:00&lt;00:00, 32.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_651ab12d48e341e0960bc8ab0c63468c"
          }
        },
        "c189046508be4d799c439e2e3026f799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8232891ef1c94430adb0e7689788359d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf73d9a8de0448bf9cfb8eaa0398562d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41f03f0390dd4eaaba69186f5f2e0c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57b2535f1e044dfcad1e3dbd1811c1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "651ab12d48e341e0960bc8ab0c63468c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1a3b9edaca14666860199facd097347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_022f6111247546e1b10e3c28d2e6e9e3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a42bb42e0bff4fed9ed637c020fbe134",
              "IPY_MODEL_bb0f45fdd51e4cb98e5507c187d3dc92",
              "IPY_MODEL_29ac15966a1341808dce4a52996b9b32"
            ]
          }
        },
        "022f6111247546e1b10e3c28d2e6e9e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a42bb42e0bff4fed9ed637c020fbe134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d05a275fae7b427497c08fb38230bf44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_230080fd79f845ccb1e4661a0b49cb7b"
          }
        },
        "bb0f45fdd51e4cb98e5507c187d3dc92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f28bec277082490db270f3a894fbf0d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 703051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 703051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f9df55093c84cc19eb1f309fb5c954b"
          }
        },
        "29ac15966a1341808dce4a52996b9b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_34e95ef9ece749e589172cccf1a66931",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 687k/687k [00:00&lt;00:00, 976kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdc69b5d83074da5859c85abf8f8b6ac"
          }
        },
        "d05a275fae7b427497c08fb38230bf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "230080fd79f845ccb1e4661a0b49cb7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f28bec277082490db270f3a894fbf0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f9df55093c84cc19eb1f309fb5c954b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34e95ef9ece749e589172cccf1a66931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdc69b5d83074da5859c85abf8f8b6ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bee4ce967f94caaa2d461fc9709ea4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e8b6f3006b04f6fa9784e595da94812",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9692bf0ce8bf42e096def24a4ceb08cb",
              "IPY_MODEL_ed6c255cb85e403799faa1bdd9faed94",
              "IPY_MODEL_4183e0ac8a9d4c55b4613c37279392a1"
            ]
          }
        },
        "2e8b6f3006b04f6fa9784e595da94812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9692bf0ce8bf42e096def24a4ceb08cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a488478f5154f1e985e48734111b8bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6e84c63aa7b436dbf21cc805a111909"
          }
        },
        "ed6c255cb85e403799faa1bdd9faed94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2508278550e4457786f2c268e350b009",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 294364,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 294364,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a51a17185384310beaf339fdb67efe9"
          }
        },
        "4183e0ac8a9d4c55b4613c37279392a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fefd294b3e6f46b8a7cf1dce91492f6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 287k/287k [00:00&lt;00:00, 1.18MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06bdc69d24f24fcd849e4e216cd272b6"
          }
        },
        "7a488478f5154f1e985e48734111b8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6e84c63aa7b436dbf21cc805a111909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2508278550e4457786f2c268e350b009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a51a17185384310beaf339fdb67efe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fefd294b3e6f46b8a7cf1dce91492f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06bdc69d24f24fcd849e4e216cd272b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a5c3d42fdb1412b818d90f68128d70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e87c950a5d4a46e9bddcee6866dbb560",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_50200253fd334a1ca96d636c4cb9b881",
              "IPY_MODEL_85578ef21db446c2968186ffefa2ae43",
              "IPY_MODEL_ff3d2e9b8b4d465fbcf4f168ac829320"
            ]
          }
        },
        "e87c950a5d4a46e9bddcee6866dbb560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50200253fd334a1ca96d636c4cb9b881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_72f48ac771a14ed5949ef0a531640a78",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9be53da116342c98490d44478eff591"
          }
        },
        "85578ef21db446c2968186ffefa2ae43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ec6c98646cb434da66cb613ba2968b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40a0e1bdb6dd41e89a6541c8bf4626c3"
          }
        },
        "ff3d2e9b8b4d465fbcf4f168ac829320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_153807c8e30a49f7aee1b0383f310d4e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.00/2.00 [00:00&lt;00:00, 38.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfad3bebb97a47d5a64f0fe8b3d6a190"
          }
        },
        "72f48ac771a14ed5949ef0a531640a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9be53da116342c98490d44478eff591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ec6c98646cb434da66cb613ba2968b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40a0e1bdb6dd41e89a6541c8bf4626c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "153807c8e30a49f7aee1b0383f310d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfad3bebb97a47d5a64f0fe8b3d6a190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25b3271a42274ca7a5fe27d7053b7520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_39e2d974520941879d37334c8ffc015b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3dc048aaba92485aa56e6926ec69e50c",
              "IPY_MODEL_c012e2452460478e99224db36beada18",
              "IPY_MODEL_16c470a1b29447449333a84992c05573"
            ]
          }
        },
        "39e2d974520941879d37334c8ffc015b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3dc048aaba92485aa56e6926ec69e50c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8888640b6a3340d7a1c2ce95d8f28f53",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bababe73d896484b860ca8b5cc348fea"
          }
        },
        "c012e2452460478e99224db36beada18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f30e5a2070ac49288cdd4cf1c9f24a65",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 12512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 12512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7fcb60c8fecb415f9c18199b69f21ed9"
          }
        },
        "16c470a1b29447449333a84992c05573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c84e7286d5e4e3a93ba38a63d6d16d6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12.2k/12.2k [00:00&lt;00:00, 329kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1d6f997d4ca49a899a58e3da6d987a1"
          }
        },
        "8888640b6a3340d7a1c2ce95d8f28f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bababe73d896484b860ca8b5cc348fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f30e5a2070ac49288cdd4cf1c9f24a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7fcb60c8fecb415f9c18199b69f21ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c84e7286d5e4e3a93ba38a63d6d16d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1d6f997d4ca49a899a58e3da6d987a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}